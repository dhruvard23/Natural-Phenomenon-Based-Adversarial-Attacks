{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11451795,"sourceType":"datasetVersion","datasetId":7175157},{"sourceId":11452049,"sourceType":"datasetVersion","datasetId":7175362},{"sourceId":11453078,"sourceType":"datasetVersion","datasetId":7175418},{"sourceId":11457277,"sourceType":"datasetVersion","datasetId":7178853}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"execution_failed":"2025-04-19T16:13:33.344Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"SEED = 42\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\n\nBATCH_SIZE = 64\nEPOCHS = 5\nTARGET_CLASSES = 16  # top-k classes to use","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# I have attached the links for the following datasets as follows\n# \"https://www.kaggle.com/datasets/akshat1012/gtsrb-resized-test-data\"\n# \"https://www.kaggle.com/datasets/akshat1012/gtsrb-resized-train-data\"\n# \"https://www.kaggle.com/datasets/akshat1012/gtsrb-csv-data\"\n\nBASE_PATH = \"/kaggle/input/gtsrb-csv-data\"\nTRAIN_CSV = os.path.join(BASE_PATH, \"Train.csv\")\nTRAIN_DIR = \"/kaggle/input/gtsrb-resized-train-data\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv(TRAIN_CSV)\nclass_counts = df['ClassId'].value_counts()\ntop_classes = sorted(class_counts[:TARGET_CLASSES].index.tolist())  # sorted for consistency (replicable)\n\nclass_id_to_index = {orig: idx for idx, orig in enumerate(top_classes)}\nindex_to_class_id = {v: k for k, v in class_id_to_index.items()}\n\nprint(\"Label Mapping:\")\nfor k, v in class_id_to_index.items():\n    print(f\"Original label {k} â†’ New index {v}\")\n\nfiltered_df = df[df['ClassId'].isin(top_classes)].reset_index(drop=True)\nfiltered_df[\"ClassId\"] = filtered_df[\"ClassId\"].map(class_id_to_index)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Organizing the dataset to load the images and labels into the the loader\n\nclass GTSRBDataset(Dataset):\n    def __init__(self, dataframe, root_dir, transform=None):\n        self.data = dataframe\n        self.root_dir = root_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        label = row['ClassId']  \n        original_class_folder = index_to_class_id[label] \n        img_path = os.path.join(self.root_dir, str(original_class_folder), row['Path'].split(\"/\")[-1])\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n\n# Resizing the images based on the models we're training\nresize_lookup = {\n    \"resnet50\": (224, 224),\n    \"densenet121\": (224, 224),\n    \"mobilenet_v2\": (224, 224),\n}\n\n# Choosing models\n\ndef get_model(name, num_classes):\n    if name == \"resnet50\":\n        model = models.resnet50(weights='IMAGENET1K_V1')\n        model.fc = nn.Linear(model.fc.in_features, num_classes)\n    elif name == \"densenet121\":\n        model = models.densenet121(weights='IMAGENET1K_V1')\n        model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n    elif name == \"mobilenet_v2\":\n        model = models.mobilenet_v2(weights='IMAGENET1K_V1')\n        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n    else:\n        raise ValueError(\"Unsupported model: \" + name)\n    return model.to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train(model, loader, val_loader, optimizer, criterion, epochs=5):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        correct = 0\n        for images, labels in tqdm(loader, desc=f\"Epoch {epoch+1}\"):\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n            correct += (outputs.argmax(1) == labels).sum().item()\n        acc = correct / len(loader.dataset)\n        print(f\"Epoch {epoch+1} - Loss: {total_loss:.4f}, Accuracy: {acc*100:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntrain_data, val_data = train_test_split(filtered_df, test_size=0.2, stratify=filtered_df[\"ClassId\"], random_state=SEED)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training the models and saving the new weights as a .pth file","metadata":{}},{"cell_type":"code","source":"model_names = [\"resnet50\", \"densenet121\", \"mobilenet_v2\"]\nfor model_name in model_names:\n    print(f\"\\n ++++ Training {model_name.upper()} ++++ \")\n    resize_dims = resize_lookup[model_name]\n\n    transform = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.Resize(resize_dims),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Normalising on the basis of ImageNet\n    ])\n\n    train_dataset = GTSRBDataset(train_data, TRAIN_DIR, transform)\n    val_dataset = GTSRBDataset(val_data, TRAIN_DIR, transform)\n\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n    model = get_model(model_name, num_classes=TARGET_CLASSES) \n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    train(model, train_loader, val_loader, optimizer, criterion, epochs=EPOCHS)\n\n    model_path = f\"/kaggle/working/{model_name}_gtsrb_top{TARGET_CLASSES}.pth\"\n    torch.save(model.state_dict(), model_path)\n    print(f\"Saved {model_name} to {model_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EVAL","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nimport pandas as pd","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"TEST_DIR = \"/kaggle/input/gtsrb-resized-test-data\"\nTRAIN_CSV = \"/kaggle/input/gtsrb-csv-data/Train.csv\"  # to regenerate mapping\nMODEL_DIR = \"/kaggle/working/\"       # Our saved models\nBATCH_SIZE = 64\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"TARGET_CLASSES = 16\ndf = pd.read_csv(TRAIN_CSV)\nclass_counts = df['ClassId'].value_counts()\ntop_classes = sorted(class_counts[:TARGET_CLASSES].index.tolist())\nclass_id_to_index = {orig: idx for idx, orig in enumerate(top_classes)}\nindex_to_class_id = {v: k for k, v in class_id_to_index.items()}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"resize_dims = (224, 224)\ntransform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.Resize(resize_dims),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class GTSRBTestDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.samples = []\n        self.transform = transform\n        for orig_class_id in top_classes:\n            class_dir = os.path.join(root_dir, str(orig_class_id))\n            if not os.path.isdir(class_dir):\n                continue\n            for img_name in os.listdir(class_dir):\n                img_path = os.path.join(class_dir, img_name)\n                mapped_label = class_id_to_index[orig_class_id]\n                self.samples.append((img_path, mapped_label))\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        img_path, label = self.samples[idx]\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            image = self.transform(image)\n        return image, label","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_model(name, num_classes):\n    if name == \"resnet50\":\n        model = models.resnet50(weights=None)\n        model.fc = nn.Linear(model.fc.in_features, num_classes)\n    elif name == \"densenet121\":\n        model = models.densenet121(weights=None)\n        model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n    elif name == \"mobilenet_v2\":\n        model = models.mobilenet_v2(weights=None)\n        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n    else:\n        raise ValueError(f\"Unsupported model: {name}\")\n    return model.to(DEVICE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate(model, dataloader):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in tqdm(dataloader, desc=\"Evaluating\"):\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            outputs = model(images)\n            preds = outputs.argmax(dim=1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluating the models on the complete test dataset","metadata":{}},{"cell_type":"code","source":"model_names = [\"resnet50\", \"densenet121\", \"mobilenet_v2\"]\ntest_dataset = GTSRBTestDataset(TEST_DIR, transform=transform)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\nfor model_name in model_names:\n    print(f\"\\n ==== Evaluating {model_name.upper()} ====\")\n    model = get_model(model_name, num_classes=TARGET_CLASSES)\n    model_path = os.path.join(MODEL_DIR, f\"{model_name}_gtsrb_top{TARGET_CLASSES}.pth\")\n    if not os.path.exists(model_path):\n        print(f\"Model file not found: {model_path}\")\n        continue\n    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n    evaluate(model, test_loader)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}